{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Kaggle Dataset using Kaggle API\n",
    "\n",
    "This Jupyter Notebook cell demonstrates how to download a dataset from Kaggle using the Kaggle API. Make sure you have your Kaggle API credentials ready before running this code. You can find your Kaggle API credentials by logging into your Kaggle account and going to the \"Account\" tab of your user profile (https://www.kaggle.com/your-username/account)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Initialize the Kaggle API client\n",
    "api = KaggleApi()\n",
    "\n",
    "# Get environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Replace with your Kaggle username and key\n",
    "api.authenticate()\n",
    "\n",
    "# Dataset name from Kaggle (e.g., 'username/dataset-name')\n",
    "dataset_name = 'mariosfish/default-of-credit-card-clients'\n",
    "\n",
    "# Destination path where you want to save the dataset\n",
    "destination_path = '../data/raw_data'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "api.dataset_download_files(dataset_name, path=destination_path, unzip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Kaggle into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  dpnm  \n",
      "0         0         0         0     1  \n",
      "1      1000         0      2000     1  \n",
      "2      1000      1000      5000     0  \n",
      "3      1100      1069      1000     0  \n",
      "4      9000       689       679     0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/raw_data/default of credit card clients.csv')\n",
    "\n",
    "# Explore the dataset (optional)\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# # Data Cleaning\n",
    "# # Remove duplicate rows (if any)\n",
    "# data.drop_duplicates(inplace=True)\n",
    "\n",
    "# # Handling missing values\n",
    "# # You can choose an appropriate strategy for handling missing data based on your dataset.\n",
    "# # For example, you can fill missing values with the mean, median, or mode of the column.\n",
    "# data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# # Feature Engineering (if required)\n",
    "# # Create new features or transform existing ones based on your analysis.\n",
    "# # Example: Creating a new feature 'total_sales' by adding 'sales_A' and 'sales_B'.\n",
    "# data['total_sales'] = data['sales_A'] + data['sales_B']\n",
    "\n",
    "# # Encoding Categorical Variables (if required)\n",
    "# # If your dataset contains categorical variables, you may need to encode them (e.g., one-hot encoding).\n",
    "# # Example: Encoding the 'category' column.\n",
    "# data = pd.get_dummies(data, columns=['category'], prefix=['category'])\n",
    "\n",
    "# # Save the preprocessed data to a new CSV file\n",
    "# data.to_csv('preprocessed_data.csv', index=False)\n",
    "\n",
    "# Optional: Data Visualization\n",
    "# You can create visualizations to explore the preprocessed data further.\n",
    "\n",
    "# Optional: Data Summary\n",
    "# You can print summary statistics or visualizations to better understand the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
