{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Kaggle Dataset using Kaggle API\n",
    "\n",
    "This Jupyter Notebook demonstrates how to download a dataset from Kaggle using the Kaggle API. Make sure you have your Kaggle API credentials ready before running this code. You can find your Kaggle API credentials by logging into your Kaggle account and going to the \"Account\" tab of your user profile (https://www.kaggle.com/your-username/account).\n",
    "\n",
    "The Data collection, cleaning, formatting and storage steps are the first step of the data science workflow:\n",
    "\n",
    "1. Data collection, cleaning, formatting and storage   <----------------- We are here\n",
    "2. Data transformation and feature engineering\n",
    "3. Statistical modeling and machine learning\n",
    "4. Visualization and presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Initialize the Kaggle API client\n",
    "api = KaggleApi()\n",
    "\n",
    "# Get environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Replace with your Kaggle username and key\n",
    "api.authenticate()\n",
    "\n",
    "# Dataset name from Kaggle (e.g., 'username/dataset-name')\n",
    "dataset_name = 'mariosfish/default-of-credit-card-clients'\n",
    "\n",
    "# Destination path where you want to save the dataset\n",
    "destination_path = '../data/raw_data'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "api.dataset_download_files(dataset_name, path=destination_path, unzip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Kaggle into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
      "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
      "1   2     120000    2          2         2   26     -1      2      0      0   \n",
      "2   3      90000    2          2         2   34      0      0      0      0   \n",
      "3   4      50000    2          2         1   37      0      0      0      0   \n",
      "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...          0          0          0         0       689         0   \n",
      "1  ...       3272       3455       3261         0      1000      1000   \n",
      "2  ...      14331      14948      15549      1518      1500      1000   \n",
      "3  ...      28314      28959      29547      2000      2019      1200   \n",
      "4  ...      20940      19146      19131      2000     36681     10000   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  dpnm  \n",
      "0         0         0         0     1  \n",
      "1      1000         0      2000     1  \n",
      "2      1000      1000      5000     0  \n",
      "3      1100      1069      1000     0  \n",
      "4      9000       689       679     0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../data/raw_data/default of credit card clients.csv')\n",
    "\n",
    "# Explore the dataset (optional)\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows dropped: 0\n",
      "Number of rows with missing all values dropped: 0\n",
      "Number of columns with missing all values dropped: 0\n",
      "Which strategy do you want for the missing values?\n",
      "1. Imputation\n",
      "2. Removal\n",
      "3. Interpolation\n",
      "4. None\n",
      "Using none.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Cleaning\n",
    "\n",
    "# Remove duplicate rows (if any)\n",
    "count_before = len(data)\n",
    "data.drop_duplicates(inplace=True)\n",
    "count_after = len(data)\n",
    "print(f\"Number of duplicate rows dropped: {count_before - count_after}\")\n",
    "\n",
    "# Remove rows that are all missing values (if any)\n",
    "count_before = len(data)\n",
    "data.dropna(how='all', inplace=True)\n",
    "count_after = len(data)\n",
    "print(f\"Number of rows with missing all values dropped: {count_before - count_after}\")\n",
    "\n",
    "# Remove columns that are all missing values (if any)\n",
    "count_before = len(data.columns)\n",
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "count_after = len(data.columns)\n",
    "print(f\"Number of columns with missing all values dropped: {count_before - count_after}\")\n",
    "\n",
    "# Decide on a strategy to handle missing values (e.g., imputation, removal, etc.)\n",
    "do_imputation = True\n",
    "while do_imputation:\n",
    "    print(f\"Which strategy do you want for the missing values?\")\n",
    "    print(f\"1. Imputation\")\n",
    "    print(f\"2. Removal\")\n",
    "    print(f\"3. Interpolation\")\n",
    "    print(f\"4. None\")\n",
    "    choice = input(\"Enter your choice: \")\n",
    "    if choice in ['1', '2', '3', '4']:\n",
    "        choice = int(choice)\n",
    "        do_imputation = False\n",
    "    else:\n",
    "        print(\"Invalid choice. Please try again.\")\n",
    "switch = {\n",
    "    1: 'imputation',\n",
    "    2: 'removal',\n",
    "    3: 'interpolation',\n",
    "    4: 'none'\n",
    "}\n",
    "print(f\"Using {switch[choice]}.\")\n",
    "match  switch:\n",
    "    case 1:\n",
    "        # Impute missing values using the mean of the column\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "    case 2:\n",
    "        # Remove rows with missing values\n",
    "        data.dropna(inplace=True)\n",
    "    case 3:\n",
    "        # Interpolate missing values using the mean of the column\n",
    "        data.interpolate(inplace=True)\n",
    "    case 4:\n",
    "        # Do nothing\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "\n",
    "destination_path = '../data/processed_data'\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "data.to_csv(os.path.join(destination_path, 'processed_data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
